{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import gym\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/CurtisIrvine/opt/anaconda3/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "#Â Define the mountain car environment \n",
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The observation space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
      "The action space: Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "# Observation and action space \n",
    "obs_space = env.observation_space\n",
    "action_space = env.action_space\n",
    "print(f\"The observation space: {obs_space}\")\n",
    "print(f\"The action space: {action_space}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to define a Q table. This is the quality of every possible action given every possible state. In most cases we will not know the bounds of our observation space. But, this gym enviroment tells us them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6  0.07]\n",
      "[-1.2  -0.07]\n"
     ]
    }
   ],
   "source": [
    "# Maximum position and momentum values\n",
    "print(obs_space.high)\n",
    "# Minimum position and momentum values\n",
    "print(obs_space.low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This observation space is continuous, thus we cannot make a table out of it. We must discretise the observation space to make a Q table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define wanted position observations \n",
    "pos_obs = 20\n",
    "# Also find the position step\n",
    "dx = (obs_space.high[0] - obs_space.low[0])/pos_obs\n",
    "\n",
    "# Define wanted momentum observations \n",
    "mom_obs = 20 \n",
    "# Also find the momentum step\n",
    "dp = (obs_space.high[1] - obs_space.low[1])/mom_obs\n",
    "\n",
    "# Fill a matrix with all possible position and momentum positions after \n",
    "# discretisation\n",
    "disc_pos = np.arange(obs_space.low[0],\n",
    "                     obs_space.high[0] + dx,\n",
    "                     dx)\n",
    "disc_mom = np.arange(obs_space.low[1],\n",
    "                     obs_space.high[1] + dp,\n",
    "                     dp)\n",
    "# Find the discretised space that is a combination of all of these\n",
    "disc_space = np.array(np.meshgrid(disc_pos, disc_mom))\n",
    "\n",
    "# The Q table dimension will be a tensor of this with the action space dimension\n",
    "# Initialise the Q table with zeros \n",
    "q_table = np.zeros((pos_obs,\n",
    "                    mom_obs,\n",
    "                    env.action_space.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that will tell us corresponding index of the \n",
    "# discrete state we are in given the continous state\n",
    "def discrete_state_index(\n",
    "    continuous_state: tuple,\n",
    "    dx: float,\n",
    "    dp: float,\n",
    "):\n",
    "    disc_state_index = (continuous_state - env.observation_space.low)/[dx, dp]\n",
    "    return discrete_state_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now define a function for updating the Q values\n",
    "# Do this without epsilon initially. May go back to change this \n",
    "def new_q_value(\n",
    "    current_q_table,\n",
    "    state_index,\n",
    "    reward,\n",
    "    learning_rate,\n",
    "    discount_factor\n",
    "):"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
